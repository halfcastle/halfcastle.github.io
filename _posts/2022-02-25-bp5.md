---
layout: post
title: ☆Blog Post 5☆
---

## Image Classification ##

tutorial to be updated!


```python
import os
from tensorflow.keras import utils 
import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras import datasets, layers, models, losses
```


```python

# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
    68608000/68606236 [==============================] - 0s 0us/step
    68616192/68606236 [==============================] - 0s 0us/step
    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.



```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

Working with datasets

Two row visualization!


```python
#fragment code in tutorial so that each applies to cats and dogs 
#(get 1 row of cats and 1 row of dogs)
classnames = ["cat", "dog"]
def visualization():
  plt.figure(figsize=(10, 10))
  k=1
  #counter to keep track of 6 pictures
  for images, labels in train_dataset.take(1):
    for i in range(len(labels)):
      #if cats
      if labels[i] == 0:
        if k<4:
          #select 3 pictures of dogs
          ax = plt.subplot(2,3,k)
          k+=1
          plt.imshow(images[i].numpy().astype("uint8"))
          plt.title(classnames[labels[i]])
          plt.axis("off")
    for i in range(len(labels)):
      if labels[i] == 1:
        if k<7:
          #select 3 pictures of dogs
          ax = plt.subplot(2,3,k)
          k+=1
          plt.imshow(images[i].numpy().astype("uint8"))
          plt.title(classnames[labels[i]])
          plt.axis("off")
```


```python
visualization()
```


    
![png](output_6_0.png)
    


Check Label Frequencies


```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
```


```python
dogs = 0
cats = 0
for label in labels_iterator:
  if label==0:
    cats+=1
  else:
    dogs+=1
print(cats, dogs)
```

    1000 1000


First Model!

In each model, include at least two Conv2D layers, at least two MaxPooling2D layers, at least one Flatten layer, at least one Dense layer, and at least one Dropout layer. Train your model and plot the history of the accuracy on both the training and validation sets. Give your model the name model1.


```python
from tensorflow.keras import models, layers
```


```python
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(2) 
    ])
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_dataset,
                    epochs=20,
                    validation_data= validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 38s 594ms/step - loss: 85.2573 - accuracy: 0.4740 - val_loss: 0.7054 - val_accuracy: 0.5458
    Epoch 2/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.6169 - accuracy: 0.6280 - val_loss: 0.7707 - val_accuracy: 0.5507
    Epoch 3/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.5165 - accuracy: 0.7195 - val_loss: 0.9236 - val_accuracy: 0.5594
    Epoch 4/20
    63/63 [==============================] - 4s 61ms/step - loss: 0.3721 - accuracy: 0.8110 - val_loss: 1.3935 - val_accuracy: 0.5730
    Epoch 5/20
    63/63 [==============================] - 4s 61ms/step - loss: 0.3132 - accuracy: 0.8555 - val_loss: 1.3153 - val_accuracy: 0.5606
    Epoch 6/20
    63/63 [==============================] - 4s 60ms/step - loss: 0.2720 - accuracy: 0.8845 - val_loss: 1.1200 - val_accuracy: 0.5780
    Epoch 7/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.2155 - accuracy: 0.9085 - val_loss: 1.7291 - val_accuracy: 0.5866
    Epoch 8/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.1563 - accuracy: 0.9360 - val_loss: 1.9089 - val_accuracy: 0.5730
    Epoch 9/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.1220 - accuracy: 0.9495 - val_loss: 2.3335 - val_accuracy: 0.5990
    Epoch 10/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.1411 - accuracy: 0.9485 - val_loss: 2.0586 - val_accuracy: 0.5408
    Epoch 11/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.1302 - accuracy: 0.9580 - val_loss: 2.3951 - val_accuracy: 0.5532
    Epoch 12/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.1160 - accuracy: 0.9620 - val_loss: 2.9967 - val_accuracy: 0.5668
    Epoch 13/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.0889 - accuracy: 0.9645 - val_loss: 3.7136 - val_accuracy: 0.5755
    Epoch 14/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.0915 - accuracy: 0.9695 - val_loss: 2.9974 - val_accuracy: 0.5693
    Epoch 15/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.1007 - accuracy: 0.9655 - val_loss: 3.0144 - val_accuracy: 0.5545
    Epoch 16/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.0793 - accuracy: 0.9725 - val_loss: 3.7012 - val_accuracy: 0.5557
    Epoch 17/20
    63/63 [==============================] - 4s 61ms/step - loss: 0.0763 - accuracy: 0.9765 - val_loss: 4.3287 - val_accuracy: 0.5866
    Epoch 18/20
    63/63 [==============================] - 4s 60ms/step - loss: 0.1350 - accuracy: 0.9620 - val_loss: 3.1909 - val_accuracy: 0.5792
    Epoch 19/20
    63/63 [==============================] - 4s 61ms/step - loss: 0.1584 - accuracy: 0.9560 - val_loss: 2.8023 - val_accuracy: 0.5681
    Epoch 20/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.0869 - accuracy: 0.9710 - val_loss: 3.7109 - val_accuracy: 0.5804



```python
plt.plot(history.history["accuracy"], label = "training", color = "violet")
plt.plot(history.history["val_accuracy"], label = "validation", color = "darkturquoise")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f52f751dd50>




    
![png](output_13_1.png)
    


Model 2 With Augmentation

Now we’re going to add some data augmentation layers to your model. Data augmentation refers to the practice of including modified copies of the same image in the training set. For example, a picture of a cat is still a picture of a cat even if we flip it upside down or rotate it 90 degrees. We can include such transformed versions of the image in our training process in order to help our model learn so-called invariant features of our input images.

First, create a tf.keras.layers.RandomFlip() layer. Make a plot of the original image and a few copies to which RandomFlip() has been applied. Make sure to check the documentation for this function!
Next, create a tf.keras.layers.RandomRotation() layer. Check the docs to learn more about the arguments accepted by this layer. Then, make a plot of both the original image and a few copies to which RandomRotation() has been applied.
Now, create a new tf.keras.models.Sequential model called model2 in which the first two layers are augmentation layers. Use a RandomFlip() layer and a RandomRotation() layer. Train your model, and visualize the training history.

Please make sure that you are able to consistently achieve at least 55% validation accuracy in this part. Scores of near 60% are possible.


```python
flippy = tf.keras.Sequential([tf.keras.layers.RandomFlip('horizontal_and_vertical'),])

for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i+1)
    augmented_image = flippy(tf.expand_dims(first_image, 0))
    #apply the layer
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```


    
![png](output_15_0.png)
    



```python
rotaty= tf.keras.Sequential([tf.keras.layers.RandomRotation(0.2),])
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = rotaty(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```


    
![png](output_16_0.png)
    


twisty cats...

now let's build model 2.


```python
model2 = models.Sequential([
    layers.RandomFlip('horizontal_and_vertical'),
    layers.RandomRotation(0.2),
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(2) 

])
```


```python
model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 65ms/step - loss: 135.6733 - accuracy: 0.5280 - val_loss: 0.7088 - val_accuracy: 0.5433
    Epoch 2/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.7106 - accuracy: 0.5525 - val_loss: 0.7080 - val_accuracy: 0.5458
    Epoch 3/20
    63/63 [==============================] - 4s 65ms/step - loss: 0.6875 - accuracy: 0.5595 - val_loss: 0.6896 - val_accuracy: 0.5792
    Epoch 4/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.6752 - accuracy: 0.5775 - val_loss: 0.6726 - val_accuracy: 0.6052
    Epoch 5/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.6834 - accuracy: 0.5785 - val_loss: 0.6671 - val_accuracy: 0.6139
    Epoch 6/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.6855 - accuracy: 0.5990 - val_loss: 0.6887 - val_accuracy: 0.5792
    Epoch 7/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.6827 - accuracy: 0.5890 - val_loss: 0.6894 - val_accuracy: 0.5953
    Epoch 8/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.6721 - accuracy: 0.6095 - val_loss: 0.6771 - val_accuracy: 0.5842
    Epoch 9/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.6762 - accuracy: 0.6000 - val_loss: 0.6650 - val_accuracy: 0.6064
    Epoch 10/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.6765 - accuracy: 0.5875 - val_loss: 0.6702 - val_accuracy: 0.6015
    Epoch 11/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.6578 - accuracy: 0.6025 - val_loss: 0.6603 - val_accuracy: 0.6040
    Epoch 12/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.6661 - accuracy: 0.5905 - val_loss: 0.6778 - val_accuracy: 0.6101
    Epoch 13/20
    63/63 [==============================] - 4s 65ms/step - loss: 0.6692 - accuracy: 0.6120 - val_loss: 0.6599 - val_accuracy: 0.6238
    Epoch 14/20
    63/63 [==============================] - 4s 65ms/step - loss: 0.6491 - accuracy: 0.6205 - val_loss: 0.6601 - val_accuracy: 0.6200
    Epoch 15/20
    63/63 [==============================] - 4s 65ms/step - loss: 0.6533 - accuracy: 0.6305 - val_loss: 0.6597 - val_accuracy: 0.6238
    Epoch 16/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.6700 - accuracy: 0.6050 - val_loss: 0.6519 - val_accuracy: 0.6126
    Epoch 17/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.6414 - accuracy: 0.6410 - val_loss: 0.6571 - val_accuracy: 0.6213
    Epoch 18/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.6545 - accuracy: 0.6145 - val_loss: 0.6563 - val_accuracy: 0.6250
    Epoch 19/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.6569 - accuracy: 0.6070 - val_loss: 0.6607 - val_accuracy: 0.6089
    Epoch 20/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.6500 - accuracy: 0.6350 - val_loss: 0.6748 - val_accuracy: 0.6027



```python
plt.plot(history.history["accuracy"], label = "training", color = "violet")
plt.plot(history.history["val_accuracy"], label = "validation", color = "darkturquoise")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f52f2ad6bd0>




    
![png](output_21_1.png)
    



```python

```

Data Preprocessing

Sometimes, it can be helpful to make simple transformations to the input data. For example, in this case, the original data has pixels with RGB values between 0 and 255, but many models will train faster with RGB values normalized between 0 and 1, or possibly between -1 and 1. These are mathematically identical situations, since we can always just scale the weights. But if we handle the scaling prior to the training process, we can spend more of our training energy handling actual signal in the data and less energy having the weights adjust to the data scale.



The following code will create a preprocessing layer called preprocessor which you can slot into your model pipeline.




```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```


```python
model3 = models.Sequential([
    preprocessor,
    layers.RandomFlip('horizontal_and_vertical'),
    layers.RandomRotation(0.2),
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(2) 

])
model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 8s 108ms/step - loss: 0.7506 - accuracy: 0.5220 - val_loss: 0.6910 - val_accuracy: 0.5470
    Epoch 2/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.6641 - accuracy: 0.5795 - val_loss: 0.6522 - val_accuracy: 0.6238
    Epoch 3/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.6495 - accuracy: 0.6175 - val_loss: 0.6317 - val_accuracy: 0.6696
    Epoch 4/20
    63/63 [==============================] - 4s 65ms/step - loss: 0.6343 - accuracy: 0.6440 - val_loss: 0.6144 - val_accuracy: 0.6522
    Epoch 5/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.6174 - accuracy: 0.6650 - val_loss: 0.6193 - val_accuracy: 0.6436
    Epoch 6/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.6030 - accuracy: 0.6735 - val_loss: 0.5803 - val_accuracy: 0.7067
    Epoch 7/20
    63/63 [==============================] - 4s 67ms/step - loss: 0.5932 - accuracy: 0.6730 - val_loss: 0.5767 - val_accuracy: 0.6918
    Epoch 8/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.5711 - accuracy: 0.6985 - val_loss: 0.5702 - val_accuracy: 0.7129
    Epoch 9/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.5670 - accuracy: 0.6960 - val_loss: 0.5635 - val_accuracy: 0.7265
    Epoch 10/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.5658 - accuracy: 0.7070 - val_loss: 0.5753 - val_accuracy: 0.7017
    Epoch 11/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.5589 - accuracy: 0.7135 - val_loss: 0.5395 - val_accuracy: 0.7339
    Epoch 12/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.5413 - accuracy: 0.7280 - val_loss: 0.5764 - val_accuracy: 0.7215
    Epoch 13/20
    63/63 [==============================] - 4s 64ms/step - loss: 0.5502 - accuracy: 0.7115 - val_loss: 0.5606 - val_accuracy: 0.7067
    Epoch 14/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.5402 - accuracy: 0.7235 - val_loss: 0.5503 - val_accuracy: 0.7364
    Epoch 15/20
    63/63 [==============================] - 4s 62ms/step - loss: 0.5287 - accuracy: 0.7295 - val_loss: 0.5439 - val_accuracy: 0.7389
    Epoch 16/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.5349 - accuracy: 0.7310 - val_loss: 0.5494 - val_accuracy: 0.7153
    Epoch 17/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.5237 - accuracy: 0.7295 - val_loss: 0.5552 - val_accuracy: 0.7129
    Epoch 18/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.5203 - accuracy: 0.7460 - val_loss: 0.5522 - val_accuracy: 0.7265
    Epoch 19/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.5114 - accuracy: 0.7505 - val_loss: 0.5356 - val_accuracy: 0.7438
    Epoch 20/20
    63/63 [==============================] - 4s 63ms/step - loss: 0.4983 - accuracy: 0.7515 - val_loss: 0.5279 - val_accuracy: 0.7364



```python
plt.plot(history.history["accuracy"], label = "training", color = "violet")
plt.plot(history.history["val_accuracy"], label = "validation", color = "darkturquoise")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f5394289d50>




    
![png](output_28_1.png)
    


nice model, no overfitting

Transfer Learning


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```


```python
model4 = models.Sequential([
    preprocessor,
    layers.RandomFlip('horizontal_and_vertical'),
    layers.RandomRotation(0.2),
    base_model_layer,
    layers.GlobalMaxPooling2D(),
    layers.Dropout(0.2),
    layers.Dense(2)
])
```


```python
model4.summary()
```

    Model: "sequential_22"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model_1 (Functional)        (None, 160, 160, 3)       0         
                                                                     
     random_flip_19 (RandomFlip)  (None, 160, 160, 3)      0         
                                                                     
     random_rotation_19 (RandomR  (None, 160, 160, 3)      0         
     otation)                                                        
                                                                     
     model_4 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                     
     global_max_pooling2d_5 (Glo  (None, 1280)             0         
     balMaxPooling2D)                                                
                                                                     
     dropout_33 (Dropout)        (None, 1280)              0         
                                                                     
     dense_40 (Dense)            (None, 2)                 2562      
                                                                     
    =================================================================
    Total params: 2,260,546
    Trainable params: 2,562
    Non-trainable params: 2,257,984
    _________________________________________________________________



```python
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 9s 76ms/step - loss: 1.0453 - accuracy: 0.7460 - val_loss: 0.1648 - val_accuracy: 0.9493
    Epoch 2/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.5559 - accuracy: 0.8645 - val_loss: 0.0975 - val_accuracy: 0.9641
    Epoch 3/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.4448 - accuracy: 0.8830 - val_loss: 0.0898 - val_accuracy: 0.9715
    Epoch 4/20
    63/63 [==============================] - 4s 68ms/step - loss: 0.4373 - accuracy: 0.8865 - val_loss: 0.0751 - val_accuracy: 0.9752
    Epoch 5/20
    63/63 [==============================] - 5s 68ms/step - loss: 0.4107 - accuracy: 0.8910 - val_loss: 0.1783 - val_accuracy: 0.9431
    Epoch 6/20
    63/63 [==============================] - 5s 68ms/step - loss: 0.3609 - accuracy: 0.9045 - val_loss: 0.0746 - val_accuracy: 0.9790
    Epoch 7/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.3969 - accuracy: 0.8960 - val_loss: 0.0977 - val_accuracy: 0.9653
    Epoch 8/20
    63/63 [==============================] - 5s 68ms/step - loss: 0.3260 - accuracy: 0.9095 - val_loss: 0.0825 - val_accuracy: 0.9765
    Epoch 9/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.3810 - accuracy: 0.9010 - val_loss: 0.0872 - val_accuracy: 0.9691
    Epoch 10/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.3236 - accuracy: 0.9135 - val_loss: 0.0879 - val_accuracy: 0.9715
    Epoch 11/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.3255 - accuracy: 0.9040 - val_loss: 0.1223 - val_accuracy: 0.9616
    Epoch 12/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.3359 - accuracy: 0.9020 - val_loss: 0.0991 - val_accuracy: 0.9641
    Epoch 13/20
    63/63 [==============================] - 4s 65ms/step - loss: 0.3139 - accuracy: 0.9080 - val_loss: 0.0758 - val_accuracy: 0.9691
    Epoch 14/20
    63/63 [==============================] - 4s 65ms/step - loss: 0.3198 - accuracy: 0.9075 - val_loss: 0.0962 - val_accuracy: 0.9703
    Epoch 15/20
    63/63 [==============================] - 4s 67ms/step - loss: 0.2878 - accuracy: 0.9105 - val_loss: 0.0621 - val_accuracy: 0.9752
    Epoch 16/20
    63/63 [==============================] - 4s 65ms/step - loss: 0.2722 - accuracy: 0.9155 - val_loss: 0.0744 - val_accuracy: 0.9752
    Epoch 17/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.3540 - accuracy: 0.9040 - val_loss: 0.0664 - val_accuracy: 0.9752
    Epoch 18/20
    63/63 [==============================] - 4s 67ms/step - loss: 0.3071 - accuracy: 0.9060 - val_loss: 0.0679 - val_accuracy: 0.9752
    Epoch 19/20
    63/63 [==============================] - 5s 68ms/step - loss: 0.2902 - accuracy: 0.9145 - val_loss: 0.0745 - val_accuracy: 0.9740
    Epoch 20/20
    63/63 [==============================] - 4s 66ms/step - loss: 0.2678 - accuracy: 0.9135 - val_loss: 0.1071 - val_accuracy: 0.9641


Looks like we have a lot of parameters. 


```python
plt.plot(history.history["accuracy"], label = "training", color = "violet")
plt.plot(history.history["val_accuracy"], label = "validation", color = "darkturquoise")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f542e536950>




    
![png](output_36_1.png)
    



```python
model4.evaluate(test_dataset)
```

    6/6 [==============================] - 1s 46ms/step - loss: 0.1093 - accuracy: 0.9583





    [0.10929068177938461, 0.9583333134651184]



nice


```python

```
